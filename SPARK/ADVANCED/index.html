
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://roadmappers.ru/SPARK/ADVANCED/">
      
      
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.16">
    
    
      
        <title>Index - ROADMAPPERS</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.7e37652d.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CFira+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Fira Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../_frontend/css/custom.css">
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#job-stage-task" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="ROADMAPPERS" class="md-header__button md-logo" aria-label="ROADMAPPERS" data-md-component="logo">
      
  <img src="../../_frontend/images/logo_v2.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            ROADMAPPERS
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Index
            
          </span>
        </div>
      </div>
    </div>
    
      
    
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/halltape/HalltapeRoadmapDE" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    Roadmappers.ru
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="ROADMAPPERS" class="md-nav__button md-logo" aria-label="ROADMAPPERS" data-md-component="logo">
      
  <img src="../../_frontend/images/logo_v2.svg" alt="logo">

    </a>
    ROADMAPPERS
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/halltape/HalltapeRoadmapDE" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.0.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path fill="currentColor" d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    Roadmappers.ru
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../page/docs/README.md" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    В начало
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#job-stage-task" class="md-nav__link">
    <span class="md-ellipsis">
      Что такое Job - Stage - Task
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    <span class="md-ellipsis">
      Почему это важно?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    <span class="md-ellipsis">
      Термины:
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_3" class="md-nav__link">
    <span class="md-ellipsis">
      Как это работает на практике?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_4" class="md-nav__link">
    <span class="md-ellipsis">
      Пример:
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spark-ui-stage" class="md-nav__link">
    <span class="md-ellipsis">
      Почему в Spark UI иногда отображается только один Stage?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_5" class="md-nav__link">
    <span class="md-ellipsis">
      Советы для оптимизации:
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_6" class="md-nav__link">
    <span class="md-ellipsis">
      Настройте партиции:
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spark-ui" class="md-nav__link">
    <span class="md-ellipsis">
      Используйте Spark UI:
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_7" class="md-nav__link">
    <span class="md-ellipsis">
      Что в итоге?
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spark" class="md-nav__link">
    <span class="md-ellipsis">
      Хинты в Spark 🪄
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spark_1" class="md-nav__link">
    <span class="md-ellipsis">
      ✳️ Основные типы хинтов в Spark
    </span>
  </a>
  
    <nav class="md-nav" aria-label="✳️ Основные типы хинтов в Spark">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#join" class="md-nav__link">
    <span class="md-ellipsis">
      🔗 Хинты для JOIN'ов
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_8" class="md-nav__link">
    <span class="md-ellipsis">
      📦 Хинты для управления партициями
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#data-skew" class="md-nav__link">
    <span class="md-ellipsis">
      ⚖️ Хинт для борьбы с перекосами (Data Skew)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#_9" class="md-nav__link">
    <span class="md-ellipsis">
      Что по синтаксису?
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_10" class="md-nav__link">
    <span class="md-ellipsis">
      Влияет ли тип джойна на выбор алгоритма?
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Влияет ли тип джойна на выбор алгоритма?">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#data-skew_1" class="md-nav__link">
    <span class="md-ellipsis">
      Что такое Data Skew, как его выявить и как с ним бороться?
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#1-broadcast-join" class="md-nav__link">
    <span class="md-ellipsis">
      1 - Broadcast Join
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-salting" class="md-nav__link">
    <span class="md-ellipsis">
      2 - Солим данные (salting)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-" class="md-nav__link">
    <span class="md-ellipsis">
      3 - Разделение данных
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4-" class="md-nav__link">
    <span class="md-ellipsis">
      4 - Оптимизация партиций
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#shuffle-spark" class="md-nav__link">
    <span class="md-ellipsis">
      Shuffle в Spark
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Shuffle в Spark">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#1-shuffle" class="md-nav__link">
    <span class="md-ellipsis">
      Шаг 1. Разбираемся, что такое shuffle
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#2-shuffle" class="md-nav__link">
    <span class="md-ellipsis">
      Шаг 2. Узнаем, когда shuffle неизбежен
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#3-shuffle" class="md-nav__link">
    <span class="md-ellipsis">
      Шаг 3. Уверенно оптимизируем shuffle
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#4" class="md-nav__link">
    <span class="md-ellipsis">
      Шаг 4. Контролируем процесс
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#5" class="md-nav__link">
    <span class="md-ellipsis">
      Шаг 5. Знать, что спросят на собеседовании (и как отвечать)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#dynamic-allocation-spark" class="md-nav__link">
    <span class="md-ellipsis">
      Dynamic Allocation в Spark: шпаргалка по настройке
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_11" class="md-nav__link">
    <span class="md-ellipsis">
      Основные алгоритмы джойнов
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Основные алгоритмы джойнов">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#_12" class="md-nav__link">
    <span class="md-ellipsis">
      Как выбрать алгоритм?
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#spark_2" class="md-nav__link">
    <span class="md-ellipsis">
      Оптимизация Spark
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


  <h1>Index</h1>

<!-- Yandex.Metrika counter -->
<script type="text/javascript">
    (function(m,e,t,r,i,k,a){
        m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};
        m[i].l=1*new Date();
        for (var j = 0; j < document.scripts.length; j++) {if (document.scripts[j].src === r) { return; }}
        k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)
    })(window, document,'script','https://mc.yandex.ru/metrika/tag.js?id=103580753', 'ym');

    ym(103580753, 'init', {ssr:true, webvisor:true, clickmap:true, ecommerce:"dataLayer", accurateTrackBounce:true, trackLinks:true});
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/103580753" style="position:absolute; left:-9999px;" alt="" /></div></noscript>
<!-- /Yandex.Metrika counter -->
<blockquote>
<p>💡 <strong>Автор материала:</strong><br />
<a href="https://t.me/iamannabo"><strong>Анна Бобкова</strong></a><br />
📡 <a href="https://t.me/chtotonainzhenernom"><strong>что-то на инженерном</strong></a> — Telegram-канал о дата инжиниринге.</p>
</blockquote>
<hr />
<h3 id="job-stage-task">Что такое Job - Stage - Task</h3>
<p align="center">
    <img src="../../png/spark_stages.jpg" alt="spark" width="600"/>
</p>

<p>Если вы только начинаете погружаться в spark, одно из первых, что нужно усвоить - это иерархию выполнения задач: Job, Stage, Task.</p>
<h3 id="_1">Почему это важно?</h3>
<p>Оптимизация, дебаггинг, настройка кластера - всё это требует знания, как Spark дробит ваши операции на этапы и задачи.  </p>
<p>Даже высокоуровневые API (DataFrames, SQL) скрывают RDD, но не отменяют логики выполнения через Job → Stage → Task.</p>
<h3 id="_2">Термины:</h3>
<p>✔️ Spark Job / Задание - это вся вычислительная задача, которую вы отправляете в Spark через действие (action), например, collect(), save(), count(). Состоит из одного или нескольких Stages.
Пример: обработка датасета от загрузки до сохранения результата.  </p>
<p>✔️ Spark Stage / Этап - логический этап выполнения Job, который объединяет задачи, не требующие обмена данными между узлами (shuffle). Разделение на Stages происходит при широких преобразованиях (например, join, groupBy, repartition), которые требуют shuffle.<br />
Пример:  filter → map → reduceByKey
Первые две операции (узкие) остаются в Stage 1, reduceByKey (широкое) запускает Stage 2.</p>
<p>✔️ Spark Task / Задача - минимальная единица работы в Spark. Каждая Task обрабатывает одну партицию данных. Выполняется параллельно на исполнителях (executors).<br />
Пример: Если ваш DataFrame имеет 200 партиций, для Stage будет создано 200 Tasks.</p>
<h3 id="_3">Как это работает на практике?</h3>
<ol>
<li>Job отправляется в spark (например, вызов df.write.csv("file")).</li>
<li>DAG Scheduler разбивает Job на Stages на основе широких преобразований.  </li>
<li>Каждая Stage делится на Tasks по числу партиций.</li>
<li>Tasks распределяются между executor’ами и выполняются параллельно.</li>
<li>Результаты Tasks объединяются, и Job завершается.</li>
</ol>
<h3 id="_4">Пример:</h3>
<div class="codehilite"><pre><span></span><code><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&quot;data.csv&quot;</span><span class="p">)</span>  
<span class="n">df_filtered</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;age&quot;</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">20</span><span class="p">)</span> <span class="c1"># Узкое преобразование (Stage 1)  </span>
<span class="n">df_repartitioned</span> <span class="o">=</span> <span class="n">df_filtered</span><span class="o">.</span><span class="n">repartition</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span> <span class="c1"># Широкое преобразование (Stage 2)  </span>
<span class="n">df_grouped</span> <span class="o">=</span> <span class="n">df_repartitioned</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="s2">&quot;city&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span> <span class="c1"># Широкое преобразование (Stage 3)  </span>
<span class="n">df_grouped</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">csv</span><span class="p">(</span><span class="s2">&quot;result&quot;</span><span class="p">)</span> <span class="c1"># Запускает Job</span>
</code></pre></div>

<p>Итог:
- 1 Job (запись в CSV),
- 3 Stages (фильтрация → репартицирование → агрегация),
- N Tasks (например, 10 задач в Stage 3 после repartition(10)).</p>
<h3 id="spark-ui-stage">Почему в Spark UI иногда отображается только один Stage?</h3>
<ul>
<li>Отсутствие операций с shuffle: если все преобразования узкие (например, filter, select), spark выполнит их в одной Stage.  </li>
<li>Оптимизация Catalyst: в spark SQL/DataFrames Catalyst Optimizer может переупорядочивать операции, избегая ненужных shuffle.
Пример: df.groupBy(...).filter(...) → фильтрация выполняется до группировки.  </li>
<li>Предварительное партиционирование: если данные уже разделены по ключу (например, после repartition("key")), groupBy может не требовать shuffle.  </li>
<li>Маленький объем данных: если данные помещаются в память одного исполнителя, spark обработает их без разделения на задачи.</li>
</ul>
<h3 id="_5">Советы для оптимизации:</h3>
<ul>
<li>Следите за shuffle: каждое широкое преобразование создает новый Stage. Используйте broadcast для небольших таблиц в join.</li>
</ul>
<h3 id="_6">Настройте партиции:</h3>
<div class="codehilite"><pre><span></span><code>➕Слишком много партиций → много мелких Tasks (риск перегрузки планировщика).
➕Слишком мало → неэффективный параллелизм.
➕Используйте coalesce для уменьшения числа партиций без shuffle.
</code></pre></div>

<h3 id="spark-ui">Используйте Spark UI:</h3>
<ul>
<li>Анализируйте время выполнения Stages (вкладка Stages), проверяйте наличие перекоса данных (Skew) и Spill (Memory/Disk).  </li>
</ul>
<h3 id="_7">Что в итоге?</h3>
<ol>
<li>Spark-приложение вызывает действие (action) → создается Job.</li>
<li>Job разбивается на Stages на основе широких преобразований.</li>
<li>Каждый Stage состоит из Tasks (по одной на партицию).  </li>
<li>Tasks выполняются на исполнителях (executors). Один исполнитель может обрабатывать несколько Tasks параллельно.</li>
</ol>
<h3 id="spark">Хинты в Spark 🪄</h3>
<p>Сегодня расскажу про «секретные команды», которые помогают оптимизировать выполнение задач, когда автоматический оптимизатор не справляется. Разберемся, какие хинты бывают, как их использовать и почему они не работают.</p>
<p><strong>Важно: хинты не гарантируют результат, но в 90% случаев spark их учитывает</strong></p>
<h2 id="spark_1">✳️ Основные типы хинтов в Spark</h2>
<h3 id="join">🔗 <strong>Хинты для JOIN'ов</strong></h3>
<p>Помогают выбрать оптимальный алгоритм соединения таблиц:</p>
<ul>
<li>
<p><strong>▫️ BROADCAST</strong><br />
  Запускает <em>Broadcast Join</em> — запускает Broadcast Join (маленькая таблица копируется на все ноды).</p>
</li>
<li>
<p><strong>▫️ MERGE</strong><br />
  Подсказывает, что данные отсортированы и можно использовать <em>Merge Join</em>.<br />
  ⚠️ Применяется только если данные <strong>заранее отсортированы</strong> по ключу соединения.</p>
</li>
<li>
<p><strong>▫️ SHUFFLE_HASH</strong><br />
  Принудительно запускает <em>Shuffle Hash Join</em>.<br />
  Полезен при соединении <strong>больших таблиц</strong>, когда ключи легко хешируются.</p>
</li>
</ul>
<h3 id="_8">📦 Хинты для управления партициями</h3>
<p>Контролируют, как данные распределяются между нодами в кластере:</p>
<ul>
<li>
<p><strong>▫️ REPARTITION</strong><br />
  Перераспределяет данные через полный shuffle, чтобы увеличить/уменьшить число партиций или партицировать по столбцу.</p>
</li>
<li>
<p><strong>▫️ COALESCE</strong><br />
  Уменьшает число партиций без shuffle (объединяет соседние).  Применяется после фильтрации, чтобы избежать мелких партиций.</p>
</li>
<li>
<p><strong>▫️ REBALANCE</strong><br />
  Автоматически балансирует данные, минимизируя перекосы.</p>
</li>
</ul>
<h3 id="data-skew">⚖️ Хинт для борьбы с перекосами (Data Skew)</h3>
<ul>
<li><strong>▫️ SKEW</strong><br />
  Указывает spark на перекошенный ключ и число партиций. </li>
</ul>
<p>Кстати, если в Spark UI видите задачи, которые выполняются в 10 раз дольше других — это skew. Попробуйте применить хинт SKEW или REBALANCE</p>
<h3 id="_9">Что по синтаксису?</h3>
<p>В sql: хинт передается в комменты /<em>+ ... </em>/ после select.</p>
<div class="codehilite"><pre><span></span><code><span class="k">SELECT</span><span class="w"> </span><span class="cm">/*+ MERGE */</span><span class="w"> </span>
<span class="w">    </span><span class="n">t1</span><span class="p">.</span><span class="o">*</span><span class="p">,</span><span class="w"> </span><span class="n">t2</span><span class="p">.</span><span class="o">*</span><span class="w"> </span>
<span class="k">FROM</span><span class="w"> </span><span class="n">table1</span><span class="w"> </span><span class="n">t1</span><span class="w"> </span>
<span class="k">JOIN</span><span class="w"> </span><span class="n">table2</span><span class="w"> </span><span class="n">t2</span><span class="w"> </span><span class="k">ON</span><span class="w"> </span><span class="n">t1</span><span class="p">.</span><span class="n">sorted_key</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">t2</span><span class="p">.</span><span class="n">sorted_key</span><span class="p">;</span>
<span class="err">В</span><span class="w"> </span><span class="n">spark</span><span class="p">:</span><span class="w"> </span><span class="err">через</span><span class="w"> </span><span class="err">метод</span><span class="w"> </span><span class="n">hint</span><span class="p">()</span>
<span class="n">df</span><span class="p">.</span><span class="n">hint</span><span class="p">(</span><span class="ss">&quot;rebalance&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;user_id&quot;</span><span class="p">)</span>
</code></pre></div>

<p><strong>Почему хинты не работают?</strong></p>
<p>— Противоречат логике оптимизатора. Например, если таблица для BROADCAST слишком большая, spark выполнит Sort-Merge Join вместо Broadcast.</p>
<p>— Версия вашего spark. Хинты вроде SKEW или REBALANCE требуют spark 3.0+</p>
<p>— Что-то в параметрах сессии. Например, включен AQE, он может переопределять хинты.</p>
<h2 id="_10">Влияет ли тип джойна на выбор алгоритма?</h2>
<p>Да, тип джойна может влиять на выбор алгоритма, но не всегда напрямую. Попробую объяснить чуть подробнее.</p>
<p>Возьмем inner join, который возвращает только совпадающие строки, ему вообще подходит любой алгоритм: но, например, Hash Join будет самым эффективным, если одна таблица помещается в память или Sort-Merge при джойне больших отсортированных таблиц.</p>
<p>Немного другая история с left/right джойнами: алгоритмы должны уметь обрабатывать отсутствующие ключи.  </p>
<p>Hash Join: в целом поддерживает left/right джойны, но требует дополнительных шагов, типа:<br />
- сохранение всех строк из главной таблицы (левой для left join)
- затем отметка отсутствующих совпадений -&gt; может потребовать больше памяти.  </p>
<p>Поэтому лучше выбрать Sort-Merge Join: так как сортировка позволяет легко найти отсутствующие ключи.  </p>
<p>Сложнее с full outer join: он возвращает все строки из обеих таблиц и требует полной обработки обеих таблиц, поэтому для него: 
- Точно нет: Nested Loop Join - неэффективен из-за сложности O(N*M).<br />
- Hash Join - можно, но редко используется, так как нужно хранить хеш-таблицы для обеих таблиц (можно встретить в PostgreSQL для небольших таблиц)
- Точно да: Sort-Merge Join - оптимальный выбор, так как сортировка позволяет объединить все данные (spark использует почти всегда)</p>
<p>Если вдруг вы решили сделать декартово произведение (cross join 🥴), то тут только Nested Loop Join (или его лучшие версии), поскольку происходит джойн каждой строки одной таблицы с каждой строкой другой. Но в spark реализовано через Shuffle.</p>
<ul>
<li>Что там с semi join? 💅🏼 </li>
<li>в целом аналогичен inner join, поэтому подойдет любой алгоритм.</li>
</ul>
<p>Для anti join - эффективен Hash Join с фильтрацией отсутствующих ключей.</p>
<p>Это все работает в случае равенства ключей (в том числе и для составных ключей).</p>
<p>❕Если ключ содержит неравенства <strong>(key_1 &gt; key_2)</strong>, то обычно работает алгоритм <strong>Nested Loop Join</strong>, для отсортированных данных - <strong>Sort-Merge Join</strong>.</p>
<h3 id="data-skew_1">Что такое Data Skew, как его выявить и как с ним бороться?</h3>
<p>Во-первых, кратко дала бы определение понятия. Data Skew - это дисбаланс в распределении данных между партициями, когда некоторые ключи содержат значительно больше записей, чем другие. Это приводит к тому, что отдельные задачи в spark выполняются дольше, возникает нагрузка на ноды, падают неприятные out of memory ошибки и падение производительности в целом. Простыми словами, одна задача обрабатывает гигантский объем данных, не справляется и падает. </p>
<p>Далее, рассказала бы как выявляю проблему. По правде говоря, проблема выявляется, когда спустя некоторое время процесс падает 🥴. Но моя лучшая версия на собесе идет и анализирует Spark UI: смотрю на метрики Shuffle Read/Write и время выполнения задач. Если вижу, что одна задача обрабатывает в 10–100 раз больше данных, чем другие - это явный признак <strong>skew</strong>.</p>
<p>Затем проверяю распределение ключей через groupBy + count.</p>
<p><strong>Например:</strong></p>
<div class="codehilite"><pre><span></span><code><span class="n">df</span><span class="o">.</span><span class="n">groupBy</span><span class="p">(</span><span class="s2">&quot;key&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">count</span><span class="p">()</span><span class="o">.</span><span class="n">orderBy</span><span class="p">(</span><span class="s2">&quot;count&quot;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">show</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div>

<p>Если несколько ключей содержат &gt;50% данных - skew присутствует. Бывает еще, что в ключе есть NULL, который собирает все в одну партицию.</p>
<p><strong>Методы решения:</strong></p>
<p>В реальной жизни у меня всегда в конфигурации сессии присутствует AQE (Adaptive Query Execution) для автоматического устранения skew:</p>
<div class="codehilite"><pre><span></span><code><span class="n">spark</span><span class="o">.</span><span class="n">conf</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="s2">&quot;spark.sql.adaptive.enabled&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span>
</code></pre></div>

<p>На собеседовании рассуждаю, что проблема решается в зависимости от контекста:</p>
<h3 id="1-broadcast-join">1 - Broadcast Join</h3>
<p>Если один из датасетов маленький — использую broadcast: </p>
<div class="codehilite"><pre><span></span><code><span class="n">df_large</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">broadcast</span><span class="p">(</span><span class="n">df_small</span><span class="p">),</span> <span class="s2">&quot;key&quot;</span><span class="p">)</span> <span class="c1"># чтобы избежать shuffle</span>
</code></pre></div>

<h3 id="2-salting">2 - Солим данные (salting)</h3>
<p>Для ключей со skew добавляю случайный префикс, чтобы равномерно распределить данные. Например, разбиваю „тяжелый“ ключ на 100 подключей, типа key_1, key_2 и т.д.</p>
<div class="codehilite"><pre><span></span><code><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">withColumn</span><span class="p">(</span><span class="s2">&quot;salted_key&quot;</span><span class="p">,</span> <span class="n">concat</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;key&quot;</span><span class="p">),</span> <span class="n">lit</span><span class="p">(</span><span class="s2">&quot;_&quot;</span><span class="p">),</span> <span class="p">(</span><span class="n">rand</span><span class="p">()</span> <span class="o">*</span> <span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="s2">&quot;int&quot;</span><span class="p">)))</span>
</code></pre></div>

<h3 id="3-">3 - Разделение данных</h3>
<p>Выделяю записи с тяжелыми ключами в отдельный датасет и обрабатываю их отдельно (например, через map-side join).</p>
<h3 id="4-">4 - Оптимизация партиций</h3>
<p>Увеличиваю число партиций через <code>spark.sql.shuffle.partitions</code> или <code>repartition()</code>, чтобы снизить нагрузку на отдельные ноды.</p>
<p>Также обязательно делимся примером из практики в стиле: на прошлом проекте делала join датасета с 10 млрд записей и маленькой таблицей-справочником. Ключ user_id был сильно перекошен: 70% данных приходилось на 5% пользователей.</p>
<p><strong>Решила проблему так:</strong></p>
<p>— Выделила тяжелых user_id в отдельный датасет.</p>
<p>— Для них применила соль с 200 подключами.</p>
<p>— Остальные данные обработала через broadcast join.</p>
<p>— Время выполнения сократилось с 3 часов до 30 минут 🎉.</p>
<p><strong>Не забудьте упомянуть, что чаще всего обращаете внимание на тюнинг spark сессии:</strong></p>
<p>— играю с параметрами spark.sql.shuffle.partitions</p>
<p>— использую kryo-сериализацию</p>
<p>— контролирую память исполнителей (spark.executor.memory, spark.memory.fraction)</p>
<p>— ну и вообще, кэширую часто используемые данные (если это уместно), как хорошая девочка 😇</p>
<h2 id="shuffle-spark">Shuffle в Spark</h2>
<p>Про shuffle в spark часто спрашивают на собеседованиях и мучают вопросами в стиле: где смотреть, куда копать. Обычно такие вопросы идут в связке с проблемой data skew.</p>
<hr />
<h3 id="1-shuffle">Шаг 1. Разбираемся, что такое shuffle</h3>
<p>Shuffle - это процесс перераспределения данных между партициями и нодами кластера. Он возникает, когда данные нужно сгруппировать, отсортировать или объединить (например, при join, groupBy, orderBy).  </p>
<p><strong>Почему он происходит?</strong></p>
<p>Данные физически разбросаны по нодам и для их обработки нужно собрать их по ключу. Пример: чтобы посчитать сумму продаж по каждому региону (<code>groupBy("region").sum()</code>), spark должен собрать все записи одного региона в одну партицию.  </p>
<hr />
<h3 id="2-shuffle">Шаг 2. Узнаем, когда shuffle неизбежен</h3>
<p><strong>Операции, которые вызывают shuffle:</strong></p>
<p>— <code>groupBy</code>, <code>reduceByKey</code>, <code>distinct</code> (агрегация)</p>
<p>— <code>join</code> (если данные не колокализованы, т.е. физически не расположены в одних и тех же партициях или на одних нодах)</p>
<p>— <code>orderBy</code>, <code>repartition</code></p>
<hr />
<h3 id="3-shuffle">Шаг 3. Уверенно оптимизируем shuffle</h3>
<p><strong>Как уменьшить объем shuffle?</strong></p>
<p>— <code>Broadcast Join</code> для маленьких таблиц. Если одна из таблиц помещается в память, её можно разослать на все ноды, избежав shuffle.</p>
<p>— Ранняя фильтрация и агрегация. Удаляем ненужные данные до операций с shuffle - это снизит нагрузку.</p>
<p><strong>Настройка партиций</strong></p>
<p>Вспоминаем чем отличается <code>repartition</code> и <code>coalesce</code>:</p>
<div class="codehilite"><pre><span></span><code>  <span class="n">df</span><span class="o">.</span><span class="n">repartition</span><span class="p">(</span><span class="mi">200</span><span class="p">,</span> <span class="s2">&quot;key&quot;</span><span class="p">)</span>  <span class="c1"># Увеличивает число партиций  </span>
  <span class="n">df</span><span class="o">.</span><span class="n">coalesce</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>            <span class="c1"># Уменьшает без Shuffle  </span>
</code></pre></div>

<p>Правильное партицирование ускоряет Shuffle, распределяя данные равномерно.
В любой непонятной ситуации применяем AQE</p>
<hr />
<h3 id="4">Шаг 4. Контролируем процесс</h3>
<p><strong>▫️Что смотреть в Spark UI:</strong></p>
<ul>
<li>Shuffle Read/Write Size: показывает объем данных, перемещенных между нодами.  </li>
<li>Disk Spills: Если высокий — увеличивайте память экзекуторов.  </li>
<li>Время выполнения этапов: этапы с shuffle обычно самые долгие.  </li>
</ul>
<p><strong>▫️Что проверить в параметрах:</strong></p>
<ul>
<li><code>spark.sql.shuffle.partitions</code>: указывает, на сколько партиций делятся данные при shuffle. 
Меньше партиций → меньше накладных расходов, но выше риск перегрузки памяти. Больше партиций → лучше параллелизм, но больше мелких файлов.  </li>
<li>spark.sql.autoBroadcastJoinThreshold: задает максимальный размер таблицы (в байтах) для автоматического <code>Broadcast Join</code>.<br />
Если таблица меньше порога, spark автоматически использует Broadcast Join, избегая shuffle.  </li>
</ul>
<p><strong>▫️Что смотреть в плане выполнения через df.explain():</strong>
- Ищите Exchange - это метка shuffle.<br />
- Определите, на каких этапах данные перемещаются между нодами.<br />
Совет: если в плане много Exchange, проверьте, можно ли заменить join на Broadcast или перепартицировать данные заранее.</p>
<p>Пример вывода:</p>
<div class="codehilite"><pre><span></span><code>   <span class="o">==</span> <span class="n">Physical</span> <span class="n">Plan</span> <span class="o">==</span>  
  <span class="o">*</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> <span class="n">Project</span> <span class="p">[</span><span class="o">...</span><span class="p">]</span>  
  <span class="o">+-</span> <span class="o">*</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span> <span class="n">SortMergeJoin</span> <span class="p">[</span><span class="o">...</span><span class="p">]</span>  
     <span class="p">:</span><span class="o">-</span> <span class="o">*</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="n">Sort</span> <span class="p">[</span><span class="o">...</span><span class="p">]</span>  
     <span class="p">:</span>  <span class="o">+-</span> <span class="n">Exchange</span> <span class="n">hashpartitioning</span><span class="p">(</span><span class="n">user_id</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>  <span class="err">←</span> <span class="n">Shuffle</span><span class="err">!</span>  
     <span class="p">:</span>     <span class="o">+-</span> <span class="n">Scan</span> <span class="n">parquet</span>  
     <span class="o">+-</span> <span class="o">*</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="n">Sort</span> <span class="p">[</span><span class="o">...</span><span class="p">]</span>  
        <span class="o">+-</span> <span class="n">Exchange</span> <span class="n">hashpartitioning</span><span class="p">(</span><span class="n">user_id</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>  <span class="err">←</span> <span class="n">Shuffle</span><span class="err">!</span>  
           <span class="o">+-</span> <span class="n">Scan</span> <span class="n">parquet</span>  
</code></pre></div>

<hr />
<h3 id="5">Шаг 5. Знать, что спросят на собеседовании (и как отвечать)</h3>
<p><strong>Что такое Shuffle?</strong></p>
<p><code>«Это перераспределение данных между нодами для группировки или сортировки. Он возникает при wide transformations, таких как groupBy или join. Данные перемещаются между партициями, что требует сетевых и дисковых операций».</code></p>
<p><strong>Как избежать Shuffle?</strong></p>
<p><code>«Использовать broadcast join, фильтровать данные заранее, применять AQE». Также можно понтануться в стиле: «я всегда анализирую Spark UI после запуска задачи. Если вижу высокий Shuffle Read, проверяю, можно ли заменить join на broadcast или перепартицировать данные заранее».</code></p>
<p><strong>Что такое skew и как с ним бороться?</strong></p>
<p><code>«Skew - это неравномерное распределение данных (например, 90% данных в одной партиции). Решения: salting (добавление случайных префиксов), увеличение числа партиций, AQE».</code> </p>
<p><strong>Чем опасен Shuffle?</strong></p>
<p><code>«Сетевые издержки, риск нехватки памяти (disk spills), skew».</code></p>
<hr />
<h2 id="dynamic-allocation-spark">Dynamic Allocation в Spark: шпаргалка по настройке</h2>
<p>В рубрике вопросы с собеседований сегодня разбираем динамическую аллокацию ресурсов. Простыми словами, это автоматическое управление количеством рабочих нод (исполнителей) в зависимости от текущей нагрузки, чтобы эффективно использовать ресурсы кластера: добавлять их при пиках задач и освобождать, когда они не нужны.</p>
<p><strong>Как включить?</strong></p>
<div class="codehilite"><pre><span></span><code><span class="n">spark</span><span class="o">.</span><span class="n">dynamicAllocation</span><span class="o">.</span><span class="n">enabled</span><span class="o">=</span><span class="n">true</span>
</code></pre></div>

<p><strong>Главные параметры</strong></p>
<p>— минимум и максимум исполнителей:</p>
<div class="codehilite"><pre><span></span><code><span class="n">spark</span><span class="o">.</span><span class="n">dynamicAllocation</span><span class="o">.</span><span class="n">minExecutors</span><span class="o">=</span><span class="mi">2</span>   <span class="c1"># ниже не опустится</span>
<span class="n">spark</span><span class="o">.</span><span class="n">dynamicAllocation</span><span class="o">.</span><span class="n">maxExecutors</span><span class="o">=</span><span class="mi">20</span>  <span class="c1"># выше не поднимется</span>
</code></pre></div>

<p>— таймаут простоя:</p>
<div class="codehilite"><pre><span></span><code><span class="n">spark</span><span class="o">.</span><span class="n">dynamicAllocation</span><span class="o">.</span><span class="n">executorIdleTimeout</span><span class="o">=</span><span class="mi">60</span><span class="n">s</span>  <span class="c1"># удаляет исполнителя через 60 сек простоя</span>
</code></pre></div>

<p><strong>Чего лучше избегать?</strong></p>
<div class="codehilite"><pre><span></span><code><span class="err">❌</span> <span class="n">executorIdleTimeout</span><span class="o">=</span><span class="mi">10</span><span class="n">s</span> <span class="err">→</span> <span class="n">постоянное</span> <span class="n">создание</span><span class="o">/</span><span class="n">удаление</span> <span class="n">исполнителей</span><span class="o">.</span>  
<span class="err">❌</span> <span class="n">maxExecutors</span><span class="o">=</span><span class="mi">1000</span> <span class="err">→</span> <span class="n">риск</span> <span class="n">перегрузить</span> <span class="n">кластер</span><span class="o">.</span>  
<span class="err">❌</span> <span class="n">не</span> <span class="n">включить</span> <span class="n">Shuffle</span> <span class="n">Service</span> <span class="n">в</span> <span class="n">YARN</span> <span class="err">→</span> <span class="n">ошибки</span> <span class="n">при</span> <span class="n">удалении</span> <span class="p">(</span><span class="n">spark</span><span class="o">.</span><span class="n">shuffle</span><span class="o">.</span><span class="n">service</span><span class="o">.</span><span class="n">enabled</span><span class="o">=</span><span class="n">true</span><span class="p">)</span>
</code></pre></div>

<p><strong>Когда Dynamic Allocation может быть неэффективен?</strong></p>
<ul>
<li>короткие задачи (&lt; 1-2 мин) → накладные расходы на масштабирование больше, чем выгода.  </li>
<li>фиксированная нагрузка → если всегда нужно 10 исполнителей, DA только мешает.</li>
<li>частые микрозадачи → DA не успевает реагировать.  </li>
<li>зависимости от конкретных нод → например, данные закэшированы на определенных исполнителях.  </li>
</ul>
<p><strong>Как проверить работу?</strong></p>
<ul>
<li>Spark UI → вкладка "Executors"</li>
<li>смотрите, как меняется число исполнителей</li>
<li>если не удаляются → проверьте Shuffle Service и таймауты</li>
</ul>
<p>Короче, dynamic allocation - это «умное» управление ресурсами.</p>
<div class="codehilite"><pre><span></span><code><span class="err">Используйте</span><span class="o">:</span><span class="w"> </span><span class="err">если</span><span class="w"> </span><span class="err">нагрузка</span><span class="w"> </span><span class="err">меняется</span><span class="w"> </span><span class="o">(</span><span class="err">пики</span><span class="o">/</span><span class="err">спады</span><span class="o">).</span><span class="w">  </span>
<span class="err">Отключайте</span><span class="o">:</span><span class="w"> </span><span class="err">если</span><span class="w"> </span><span class="err">задачи</span><span class="w"> </span><span class="err">короткие</span><span class="o">,</span><span class="w"> </span><span class="err">фиксированные</span><span class="w"> </span><span class="err">или</span><span class="w"> </span><span class="err">требуют</span><span class="w"> </span><span class="err">жесткого</span><span class="w"> </span><span class="err">контроля</span><span class="o">.</span>
</code></pre></div>

<h2 id="_11">Основные алгоритмы джойнов</h2>
<p align="center">
    <img src="../../png/spark_join.jpg" alt="spark" width="600"/>
</p>

<p><code>Next level для тех, кто освоил типы джойнов, и теперь готов к оптимизации своих запросов 😎</code></p>
<p>Ниже приведены ключевые алгоритмы джойнов, используемые в реляционных СУБД и распределенных системах (Spark, Hadoop). Каждый из них решает определенные задачи в зависимости от объема данных, их структуры и инфраструктуры.</p>
<hr />
<p><strong>▫️Nested Loop Join</strong> - для каждой строки левой таблицы сканируется вся правая таблица (вложенные циклы).
- подходит для очень маленьких таблиц (до 1 тыс. строк)
- используется в SQLite, PostgreSQL для простых запросов
- простая реализация
- не требует сортировки или индексов
- сложность <code>O(N*M)</code> → неприменим для больших данных.  </p>
<hr />
<p><strong>▫️Hash Join</strong> - состоит из двух фаз:</p>
<p><code>Build Phase: создается хеш-таблица для меньшей таблицы.</code></p>
<p><code>Probe Phase: большая таблица итерируется, и ключи ищутся в хеш-таблице.</code></p>
<ul>
<li>используется, если одна таблица помещается в память (справочники, малые датасеты), например в PostgreSQL для джойна пользователей и заказов.  </li>
<li>быстрый поиск за счет хешей → O(N + M).</li>
<li>не требует сортировки.  </li>
<li>требует много памяти.  </li>
<li>неэффективен для skewed-ключей.  </li>
</ul>
<hr />
<p><strong>▫️Sort-Merge Join</strong> - сначала обе таблицы сортируются по ключу джойна. Далее происходит слияние отсортированных данных (как в алгоритме двух указателей).</p>
<ul>
<li>подходит для больших таблиц, которые нельзя броадкастить, и если данные уже отсортированы (например, партиционированы по дате).  </li>
<li>стабильная работа на больших данных.</li>
<li>минимизирует использование памяти.  </li>
<li>дорогая сортировка → O(N log N + M log M)</li>
<li>не подходит для skewed data.  </li>
</ul>
<hr />
<p><strong>▫️Broadcast Join (Map-Side Join)</strong> - маленькая таблица рассылается на все ноды кластера. Джойн выполняется локально на каждой ноде без <code>Shuffle</code>. </p>
<ul>
<li>используется, если маленькая таблица ≤ 10% памяти ноды (справочники, конфигурации), например для джойна логов и справочника стран на spark. </li>
<li>нет Shuffle → экономия сети.  </li>
<li>максимальная скорость для маленьких таблиц.  </li>
<li>риск OOM, если таблица слишком большая.  </li>
</ul>
<hr />
<p><strong>▫️Shuffle Hash Join</strong> - обе таблицы перемешиваются (Shuffle) по ключу.  На каждой ноде строится хеш-таблица для одной из таблиц.</p>
<ul>
<li>подходит для больших таблиц, когда одна из них после фильтрации помещается в память.</li>
<li>быстрее Sort-Merge для средних данных.  </li>
<li>риск spill на диск при нехватке памяти.  </li>
</ul>
<hr />
<p><strong>▫️Bucket Join</strong> - данные предварительно разбиваются на бакеты по ключу, затем джоин выполняется между соответствующими бакетами. Подходит для частых джойнов по одному ключу (ETL-пайплайны).</p>
<hr />
<p><strong>▫️Skew Join</strong> - добавление случайного префикса (соли) к «тяжелым» ключам для распределения нагрузки. Далее происходит динамическое разбиение: дробление партиций с skewed-ключами. Подходит для данных с сильным перекосом (например, 80% записей по одному ключу).  </p>
<hr />
<p><strong>▫️Grace Hash Join</strong> - комбинация Hash Join и внешней сортировки. Если хеш-таблица не влезает в память, данные разбиваются на партиции и обрабатываются по частям. Подходит для очень больших таблиц, которые не помещаются в память. </p>
<hr />
<h3 id="_12">Как выбрать алгоритм?</h3>
<p><strong>1 — смотрим на размер данных:</strong></p>
<p><code>Небольшая таблица → Broadcast Join</code></p>
<p><code>Большие таблицы → Sort-Merge или Shuffle Hash</code></p>
<p><strong>2 — смотрим на структуру данных:</strong></p>
<p><code>Отсортированы → Sort-Merge</code></p>
<p><code>Skewed-ключи → Skew Join</code></p>
<p><strong>3 — инфраструктура:</strong></p>
<p><code>Spark → используйте хинты (BROADCAST, MERGE)</code></p>
<p><code>Реляционная СУБД → опирайтесь на планировщик и индексы</code></p>
<p><strong>❕Запомнить:</strong></p>
<ul>
<li>Nested Loop и Hash Join - база для СУБД.  </li>
<li>Broadcast и Sort-Merge - основа для распределенных систем.  </li>
<li>Всегда анализируйте план выполнения (explain в SQL, df.explain() в Spark) + метрики (память, сеть).</li>
</ul>
<hr />
<h2 id="spark_2">Оптимизация Spark</h2>
<p>Рекомендую очень годные статьи про Spark: </p>
<p><a href="https://habr.com/ru/articles/896492/">Как Apache Spark читает файлы</a>  </p>
<p><a href="https://habr.com/ru/articles/901078/">Оптимизация запросов в Apache Spark</a>  </p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      MIT
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": [], "search": "../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.50899def.min.js"></script>
      
        <script src="../../_frontend/js/toc-home.js"></script>
      
        <script src="../../_frontend/js/scroll-to-top.js"></script>
      
    
  </body>
</html>